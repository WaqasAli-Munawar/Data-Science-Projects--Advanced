{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most companies, the story usually goes like this.\n",
    "1. A customer calls in to complain, praise, or ask for assistance.\n",
    "2. The call is recorded for further training or evaluation.\n",
    "3. The recording is typically picked at random, listened to by someone, and reviewed with the customer service representative.\n",
    "\n",
    "This process can take anywhere from an hour to a week after a customer hangs up. During this time, a lot can go wrong. Compliance issues and poor service could leave us with some unhappy customers. We’re going to show you how to work smarter, not harder, and identify problems as soon as they occur. What most developers don’t realize is that the intricate pieces pre-built inside the Google Cloud Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three essential items we will want to look for when evaluating a call.\n",
    "* **Identity** — Separate the individuals on the call distinctly.\n",
    "* **Sentiment** — Are these individuals generally positive or negative in the interaction.\n",
    "* **Trigger Words** — Were any words or phrases said that warrant further review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s complicate this a bit and evaluate single-channel audio phone calls. Complexity means we are not only dealing with call quality type audio, but also audio where each caller co-mingles in a single channel. Single channels make it much harder to distinguish who is talking and when.\n",
    "\n",
    "A Google Cloud Function is the easiest way to trigger code execution at scale when a file is uploaded to Cloud Storage. [Setting up a Cloud Function](https://cloud.google.com/functions/docs/tutorials/storage#functions-change-directory-python) for this purpose is easy and straight forward.\n",
    "\n",
    "Let’s first start with the **requirements.txt** file and imports.\n",
    "\n",
    "### Requirements.txt\n",
    "`google-cloud-speech==1.3.2\n",
    "google-cloud-storage==1.27.0\n",
    "pathlab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports\n",
    "\n",
    "In this example, we will be using diarization to distinguish and separate the audio between the two callers. [Diarization](https://en.wikipedia.org/wiki/Speaker_diarisation#:~:text=Speaker%20diarisation%20(or%20diarization)%20is,according%20to%20the%20speaker%20identity.) is **The process of partitioning an input audio stream into homogeneous segments according to the speaker identity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-cloud-speech --user\n",
    "# pip install google-cloud\n",
    "# pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process requires Cloud **Speech beta** module `speech_v1p1beta1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1\n",
    "# from google.cloud.speech_v1p1beta1 import enums # The submodules enums and types have been removed.\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submodules **enums** and **types** have been removed. Please see this [page](https://github.com/googleapis/python-speech/blob/master/UPGRADING.md#enums-and-types). \n",
    "\n",
    "Along the same lines usage of nanos attributes would result in the following message if we have update the api\n",
    "\n",
    "`AttributeError: 'datetime.timedelta' object has no attribute 'nanos'`\n",
    "\n",
    "Please see this [page](https://github.com/googleapis/python-speech/issues/71). Use `microseconds` instead of `nanos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the created file\n",
    "\n",
    "As the Cloud Function is triggered by a `google.storage.object.finalize` event inside GCS, a dictionary with data specific to this type of event is sent.\n",
    "\n",
    "Grabbing the path of the file name is as easy as pulling out the object `file[\"name\"]` from the [dictionary](https://cloud.google.com/functions/docs/calling/storage). Knowing all this information, we can build out a `gs://` URI that can be used for various Google AI services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing the Audio\n",
    "\n",
    "Before transcribing the audio, we first want to make sure it is an actual audio file. In this example, we are only going to deal with **mp3** audio. There are a tremendous amount of options to choose from, and we will highlight a few. \n",
    "\n",
    "First, the **hertz rate** is essential, and more often than not, is **8000 for phone audio recordings**. Second, because this is a phone call, it is different.\n",
    "\n",
    "Google has a different Machine Learning model for phone call audio that creates a better transcription overall. Finally, for proper configuration, make sure to enable diarization and set the appropriate amount of speakers on the call. If required, auto-adjust our utterance dictionary and pick out specific pronouns, business names, or phrases that can show up in conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BucketName = 'gcs-bucket'\n",
    "\n",
    "def transcribe_audio(event, context):\n",
    "    file = event\n",
    "    now = time.time()\n",
    "    FileName = file['name']\n",
    "    storage_uri = 'gs://' + BucketName + '/' + FileName\n",
    "    \n",
    "    # Let's process only mp3 files\n",
    "    if storage_uri[-4:] ==\".mp3\":\n",
    "        client = speech_v1p1beta1.SpeechClient()\n",
    "        sample_rate_hertz = 8000 # Sample rate in Hertz of the audio data sent\n",
    "        language_code = \"en-US\" # The language of the supplied audio\n",
    "        model = \"phone_call\"\n",
    "        \n",
    "        # Encoding of audio data sent. This sample sets this explicitly.\n",
    "        # This field is optional for FLAC and WAV audio formats.\n",
    "        # encoding = enums.RecognitionConfig.AudioEncoding.MP3 # The submodules enums has been removed.\n",
    "        encoding = speech_v1p1beta1.RecognitionConfig.AudioEncoding.MP3\n",
    "        config = {\n",
    "            \"sample_rate_hertz\": sample_rate_hertz,\"language_code\": language_code,\n",
    "            \"encoding\": encoding,\"model\": model,\"use_enhanced\": True,\n",
    "            \"enable_automatic_punctuation\": True,\"enable_speaker_diarization\": True,\n",
    "            \"diarization_speaker_count\": 2,\n",
    "            \"speech_contexts\": [{\"phrases\": [\"Thank you for calling ABC\",\n",
    "                                             \"Thank you for contacting ABC\",\"Welcome to ABC\",\n",
    "                                             \"ABC customer service\",\n",
    "                                             \"Thank you for calling ABC customer support.\"]}]}\n",
    "        audio = {\"uri\": storage_uri}\n",
    "        \n",
    "        operation = client.long_running_recognize(config, audio)\n",
    "        #print(\"Waiting for operation to complete...\")\n",
    "        response = operation.result()\n",
    "        transcript = \"\"\n",
    "        transcriptw = \"\"\n",
    "        sendtrans = False\n",
    "        keyword = \"Empty Audio\"\n",
    "        speaker = \"\"\n",
    "        \n",
    "        for result in response.results:\n",
    "            words_info = result.alternatives[0].words\n",
    "            for word_info in words_info:\n",
    "                if str(word_info.speaker_tag) != \"0\":\n",
    "                    if str(word_info.speaker_tag) != str(speaker):\n",
    "                        #print(str(word_info.speaker_tag) + \" is not \" + str(speaker))\n",
    "                        speaker = str(word_info.speaker_tag)\n",
    "                        transcriptw = transcriptw + \"\\n-------\\n*Speaker \" + speaker + \":* \" + word_info.word\n",
    "                    else:\n",
    "                        #print(str(word_info.speaker_tag) + \" is \" + speaker)\n",
    "                        transcriptw = transcriptw + \" \" + word_info.word\n",
    "                        speaker = str(word_info.speaker_tag)\n",
    "        \n",
    "        sendtrans = False\n",
    "        keyword = \"Empty Audio\"\n",
    "        print(transcriptw)\n",
    "\n",
    "        if transcriptw.strip() == \"\":\n",
    "            transcriptw = \"*No Sound*\"\n",
    "            sendtrans = True\n",
    "        else:\n",
    "            list = [\"bitcoin\",\"payment\", \"invoice\", \"bill\", \"utilities\", \"utility\", \"electricity\", \n",
    "                    \"credit card\", \"package\", \"testing\",\"kits\",\"financial\", \"supplies\", \"mask\",\n",
    "                    \"symptoms\", \"isolate\",\"oxygen\",\"ventilator\",\"social security\",\"government\",\n",
    "                    \"internal revenue\",\"covid\", \"world health\", \"national institute\", \"virus\", \n",
    "                    \"corona\",\"quarantine\",\"stimulus\",\"relief\",\"cdc\",\"disease\",\"pandemic\",\"epidemic\",\n",
    "                    \"sickness\"] \n",
    "            # Using for loop \n",
    "            for i in list: \n",
    "                if i.lower() in transcriptw.lower():\n",
    "                    keyword = i.lower()\n",
    "                    sendtrans = True\n",
    "                    break\n",
    "\n",
    "        if sendtrans == True:\n",
    "            print(f\"Sending to Slack: {file['name']}.\")\n",
    "            filename = file['name']\n",
    "            send_slack(transcript.strip(),filename,keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Longer audio such as entire phone conversations, the best practice is to use the `client.long_running_recognize(config, audio)` method. This method performs asynchronous speech recognition.\n",
    "\n",
    "After transcribing, we check the transcript for any keyword triggers and, if any match, send the transcription to slack for immediate notification. Below is the slack function `send_slack(transcriptw,filename,keyword)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_slack(transcript,filename,keyword):\n",
    "    try:\n",
    "        response = requests.post(url=\"https://hooks.slack.com/services/ABCDEFG/123456/ABC123\",\n",
    "                                 headers={\"Content-Type\": \"application/json\"},\n",
    "                                 data=json.dumps({\"text\": \"*Audio:* https://storage.cloud.google.com/\" + BucketName + \"/\" + filename + \"\\n*Transcription:*\\n\" + transcript}))\n",
    "        print('Response HTTP Status Code: {status_code}'.format(status_code=response.status_code))\n",
    "        print('Response HTTP Response Body: {content}'.format(content=response.content))\n",
    "    except requests.exceptions.RequestException:\n",
    "        print('HTTP Request failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An open-source and simplified example of the above code is in one of **Ytel’s public [Gitlab repositories](https://gitlab.com/ytelprojects/covid-19-compliance-module)**. Telecom companies needed to identify and report certain types of scam oriented communications when the Covid-19 outbreak started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

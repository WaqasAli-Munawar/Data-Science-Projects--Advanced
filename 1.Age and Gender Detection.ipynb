{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and Gender Detection is the task of **Computer Vision** so we will be using **OpenCV** library. However before getting started with this task, we will first go through the concept and how to deal with the problem of age and gender detection.\n",
    "\n",
    "Understanding the concept is important so that in future we can easily perform related task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Age and Gender Detection\n",
    "\n",
    "The task of detecting age and gender, however, is an inherently difficult problem, more than many other computer vision tasks. The main reason for this difficulty, gap lies in the data required to train these types of systems.\n",
    "\n",
    "While general object detection tasks can often have access to hundreds of thousands or even millions of images for training, datasets with age and/or gender labels are considerably smaller, usually in the thousands or, at best, tens of thousands. The reason is that, to have tags for such images, we need to access the personal information of the subjects in the images. Namely, we would need their date of birth and gender, and in particular date of birth is infrequently published information. Therefore, we have to settle for the nature of this problem that we are addressing and adapt network architectures and algorithmic approaches to deal with these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The areas of classification by age and sex have been studied for decades. Various approaches have been taken over the years to tackle this problem, with varying levels of success.\n",
    "\n",
    "We will present the problem of gender detection as a classification problem and the age detection problem as a regression problem. However, estimating age accurately using regression is difficult. Even humans cannot accurately predict an age by looking at a person. However, we do know if they are in their `30s` or `40s`. This is also what we are going to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now letâ€™s get started with the task of Age and Gender detection. We will first start with writing the code for detecting faces because without face detection we will not be able to move further with the task of age and gender prediction.\n",
    "\n",
    "We can download the necessary OpenCV pre-trained models that we will need in the task of age and gender detection from [here](https://drive.google.com/file/d/1yy_poZSFAPKi0y2e2yj9XDe1N8xXYuKB/view) or [here](https://github.com/opencv/opencv/tree/master/data/haarcascades). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "import cv2\n",
    "import math\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to predict gender and age in the image. We will load the gender and ageing network into memory and transmit the detected face across the network for the gender and age detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image IMAGE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Waqas.Ali\\AppData\\Roaming\\jupyter\\runtime\\kernel-738ac2ab-2a39-4a54-8934-282b62f54ab1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser=argparse.ArgumentParser()\n",
    "parser.add_argument('--image')\n",
    "\n",
    "args=parser.parse_args()\n",
    "\n",
    "faceProto=\"cv/opencv_face_detector.pbtxt\"\n",
    "faceModel=\"cv/opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"cv/age_deploy.prototxt\"\n",
    "ageModel=\"cv/age_net.caffemodel\"\n",
    "genderProto=\"cv/gender_deploy.prototxt\"\n",
    "genderModel=\"cv/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']\n",
    "\n",
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)\n",
    "\n",
    "video=cv2.VideoCapture(args.image if args.image else 0)\n",
    "padding=20\n",
    "while cv2.waitKey(1)<0:\n",
    "    hasFrame,frame=video.read()\n",
    "    if not hasFrame:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "\n",
    "    resultImg,faceBoxes=highlightFace(faceNet,frame)\n",
    "    if not faceBoxes:\n",
    "        print(\"No face detected\")\n",
    "\n",
    "    for faceBox in faceBoxes:\n",
    "        face=frame[max(0,faceBox[1]-padding):\n",
    "                   min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                   :min(faceBox[2]+padding, frame.shape[1]-1)]\n",
    "        \n",
    "        # Code for Gender Detection:\n",
    "        blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds=genderNet.forward()\n",
    "        gender=genderList[genderPreds[0].argmax()]\n",
    "        print(\"Gender Output : {}\".format(genderPreds))\n",
    "        print(f'Gender: {gender}')\n",
    "\n",
    "        # Code for Age Detection:\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds=ageNet.forward()\n",
    "        age=ageList[agePreds[0].argmax()]\n",
    "        print(\"Age Output : {}\".format(agePreds))\n",
    "        print(f'Age: {age[1:-1]} years')\n",
    "        \n",
    "        #  last code we need to write is to display the output:\n",
    "        label = f'{gender}, {age}'\n",
    "        cv2.putText(resultImg, label, (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                    (0,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Detecting age and gender\", resultImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot experiment with this easily in ipython as the ipython command line will be used per default in `parse_args`. Try this with a normal `*.py` file and the python executable to launch that file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run following on command line\n",
    "\n",
    "`python gender_age.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybi5E_LLQeb5"
   },
   "source": [
    "In this file, we will work on how we can classify the nationalities of people by using their names. There is a lot about how we can play with names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ND7w0dxQeb-"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "52tNGS07QecB"
   },
   "outputs": [],
   "source": [
    "# f_url = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/Indian-Female-Names.csv\"\n",
    "# m_url = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/Indian-Male-Names.csv\"\n",
    "\n",
    "# male_data = pd.read_csv(m_url)\n",
    "# female_data = pd.read_csv(f_url)\n",
    "\n",
    "male_data = pd.read_csv(\"nationality/male_names.csv\")\n",
    "female_data = pd.read_csv(\"nationality/female_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "t_VE0n18QecD",
    "outputId": "35375ff6-d4e3-4c52-bd93-60082eacc8a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shivani</td>\n",
       "      <td>f</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isha</td>\n",
       "      <td>f</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smt shyani devi</td>\n",
       "      <td>f</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>divya</td>\n",
       "      <td>f</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mansi</td>\n",
       "      <td>f</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name gender    race\n",
       "0          shivani      f  indian\n",
       "1             isha      f  indian\n",
       "2  smt shyani devi      f  indian\n",
       "3            divya      f  indian\n",
       "4            mansi      f  indian"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw7OW-VbQecG"
   },
   "source": [
    "Now we are creating helper functions for data cleaning and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "weEHzbm2QecH"
   },
   "outputs": [],
   "source": [
    "repl_list = ['s/o','d/o','w/o','/','&',',','-']\n",
    "\n",
    "def clean_data(name):\n",
    "    name = str(name).lower()\n",
    "    name = (''.join(i for i in name if ord(i)<128)).strip()\n",
    "    for repl in repl_list:\n",
    "        name = name.replace(repl,\" \")\n",
    "    if '@' in name:\n",
    "        pos = name.find('@')\n",
    "        name = name[:pos].strip()\n",
    "    name = name.split(\" \")\n",
    "    name = \" \".join([each.strip() for each in name])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YTpu1-enQecI"
   },
   "outputs": [],
   "source": [
    "def remove_records(merged_data):\n",
    "    merged_data['delete'] = 0\n",
    "    merged_data.loc[merged_data['name'].str.find('with') != -1,'delete'] = 1\n",
    "    merged_data.loc[merged_data['count_words']>=5,'delete']=1\n",
    "    merged_data.loc[merged_data['count_words']==0,'delete']=1\n",
    "    merged_data.loc[merged_data['name'].str.contains(r'\\d') == True,'delete']=1\n",
    "    cleaned_data = merged_data[merged_data.delete==0]\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2OdijCnZQecL"
   },
   "outputs": [],
   "source": [
    "merged_data = pd.concat((male_data,female_data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "weYpwUMLQecS"
   },
   "outputs": [],
   "source": [
    "merged_data['name'] = merged_data['name'].apply(clean_data)\n",
    "merged_data['count_words'] = merged_data['name'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aboy5IzeQecW"
   },
   "outputs": [],
   "source": [
    "cleaned_data = remove_records(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bwAazu-qQecX"
   },
   "outputs": [],
   "source": [
    "indian_cleaned_data = cleaned_data[['name','count_words']].drop_duplicates(subset='name',keep='first')\n",
    "indian_cleaned_data['label'] = 'indian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ekz37LNwQecY",
    "outputId": "58b4590f-9181-4cb4-ca38-3dd7c122d728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13754"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indian_cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVovJx6XQecZ"
   },
   "source": [
    "After loading and removing the wrong entries in the data, we got a few records around 13,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rsyRUa1YQeca",
    "outputId": "36c5ab53-3a54-4046-c24e-439c801ef092"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>count_words</th>\n",
       "      <th>delete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barjraj</td>\n",
       "      <td>m</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramdin verma</td>\n",
       "      <td>m</td>\n",
       "      <td>indian</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharat chandran</td>\n",
       "      <td>m</td>\n",
       "      <td>indian</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>birender mandal</td>\n",
       "      <td>m</td>\n",
       "      <td>indian</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amit</td>\n",
       "      <td>m</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name gender    race  count_words  delete\n",
       "0          barjraj      m  indian            1       0\n",
       "1     ramdin verma      m  indian            2       0\n",
       "2  sharat chandran      m  indian            2       0\n",
       "3  birender mandal      m  indian            2       0\n",
       "4             amit      m  indian            1       0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPEhi_Z1Qecb",
    "outputId": "a9ed5cd1-bbcc-40a8-8770-675ef788aed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indian    30227\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rn5CJeHRQecc",
    "outputId": "34aab139-f790-4d3a-fe34-88f93408a9b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barjraj</td>\n",
       "      <td>1</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramdin verma</td>\n",
       "      <td>2</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharat chandran</td>\n",
       "      <td>2</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>birender mandal</td>\n",
       "      <td>2</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amit</td>\n",
       "      <td>1</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  count_words   label\n",
       "0          barjraj            1  indian\n",
       "1     ramdin verma            2  indian\n",
       "2  sharat chandran            2  indian\n",
       "3  birender mandal            2  indian\n",
       "4             amit            1  indian"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6uLZzkxQecc"
   },
   "source": [
    "Lets create some non-Indian names using Faker - a pretty cool package to generate realistic names from different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1yKZ6TB8Qecd"
   },
   "outputs": [],
   "source": [
    "# pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "X7yc3sYnQecd",
    "outputId": "955f5083-1f49-43e9-cfb3-7173d9a4e22b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Alexandra Bennett'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "fake = Faker(\"en_US\")\n",
    "fake.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8n-1fH4xQece"
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "req = 15000\n",
    "non_indian_names = []\n",
    "\n",
    "langs = ['ar_EG','bs_BA','de_DE','dk_DK','en_AU','en_CA','en_GB',\n",
    "'en_IN','en_NZ','en_US','it_IT','no_NO','ro_RO']\n",
    "\n",
    "for i in range(0,req):\n",
    "    lng_indx = random.randint(0,len(langs)-1)\n",
    "    fake = Faker(langs[lng_indx])\n",
    "    non_indian_names.append(fake.name().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dtNon8WFQece"
   },
   "outputs": [],
   "source": [
    "non_indian_names_orig = list(set(non_indian_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6txbsTAHQecf",
    "outputId": "8cc8da65-953e-4e59-a324-5cdd6ea2bf60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14664"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_indian_names_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "keVkuhqJQecg"
   },
   "outputs": [],
   "source": [
    "non_indian_data = pd.DataFrame({'name':non_indian_names_orig})\n",
    "non_indian_data['count_words'] = non_indian_data['name'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqjMh-nUQech"
   },
   "source": [
    "We have generated approximately the same number of names as we have in the Indian data set. We then removed samples longer than 5 words. The Indian data set contained a lot of names with just first names. So we need to make the overall non-Indian distribution also similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Ib_9Bb-ZQech",
    "outputId": "cba81fe0-dc79-442b-cc49-51731dd0b9c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reece nash</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>veronica harris</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suzanne green-garner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>derek eaton</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melissa harrison</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  count_words\n",
       "0            reece nash            2\n",
       "1       veronica harris            2\n",
       "2  suzanne green-garner            2\n",
       "3           derek eaton            2\n",
       "4      melissa harrison            2"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_indian_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnnMiq2nQeci"
   },
   "source": [
    "Lets check the distribution of count of words in names. We dont want them to be too different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B39JEmyfQeci",
    "outputId": "7da2d6e2-81a5-49bc-e23a-dafe25ab99bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7954\n",
       "1    4322\n",
       "3    1344\n",
       "4     134\n",
       "Name: count_words, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_cleaned_data['count_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFdxDmazQeci",
    "outputId": "2dee99ad-4615-4f57-eae5-4a3a07b6ffae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    13058\n",
       "3     1422\n",
       "4      179\n",
       "5        5\n",
       "Name: count_words, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_indian_data['count_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inAN5BMPQecj",
    "outputId": "d7c84afe-ea92-4e63-81ea-7bb573b8d815"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    8058\n",
       "1    5000\n",
       "3    1422\n",
       "4     179\n",
       "Name: count_words, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_word_names = non_indian_data[non_indian_data['count_words']==2]['name']\n",
    "one_word_req = 5000\n",
    "names_one_two_words = [each.split()[0] for each in two_word_names[:one_word_req]] + list(two_word_names[one_word_req:])\n",
    "count_words = [1] * one_word_req + [2] * len(two_word_names[one_word_req:])\n",
    "not_two_words_pd  = non_indian_data[non_indian_data['count_words']!=2]\n",
    "one_two_words_pd = pd.DataFrame({'name':names_one_two_words,'count_words':count_words})\n",
    "non_indian_data = pd.concat((not_two_words_pd,one_two_words_pd),axis=0)\n",
    "non_indian_data['count_words'].value_counts()\n",
    "non_indian_data['label'] = 'non_indian'\n",
    "non_indian_data = non_indian_data[non_indian_data['count_words']<5]\n",
    "non_indian_data['count_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ZTet3XZFQecj",
    "outputId": "83755064-37d1-4972-831b-9bce0ed16263"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10640</th>\n",
       "      <td>hr frederik sørensen</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>sig. giampaolo bosio</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>rinukanwr</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>austin torres</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>raju garg</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name       label\n",
       "10640  hr frederik sørensen  non_indian\n",
       "8752   sig. giampaolo bosio  non_indian\n",
       "227               rinukanwr      indian\n",
       "6921          austin torres  non_indian\n",
       "548               raju garg      indian"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat((non_indian_data[['name','label']],indian_cleaned_data[['name','label']]),axis=0)\n",
    "name_data = full_data.sample(frac=1)\n",
    "\n",
    "# full_data.to_csv(\"name_data.csv\",index=False)\n",
    "# from google.colab import files\n",
    "# files.download('name_data.csv')\n",
    "\n",
    "name_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "uu9zzBhuQeck"
   },
   "outputs": [],
   "source": [
    "# data_url = \"https://raw.githubusercontent.com/ashavish/name-nationality/master/data/name_data.csv\"\n",
    "# name_data = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7W4MxWM4Qecl",
    "outputId": "72c3fb3b-071e-4ea4-b532-d296068d01a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non_indian    14659\n",
       "indian        13754\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uajDzpzQecl"
   },
   "source": [
    "We end up with about 14,000 non-Indian names and 13,000 Indian names. Now let’s build a neural network to classify nationalities using names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "71NnZTn9Qecm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = name_data['name'].astype(str)\n",
    "Y = name_data['label']\n",
    "train_names,test_names,train_labels,test_labels = train_test_split(X,Y,test_size=0.20,random_state =42,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFCR23IeQecm"
   },
   "source": [
    "### Naive Bayes with Count Vectorizer for name classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfiNYzICQecm",
    "outputId": "347e26e0-d5e3-410c-95f1-c63987064351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11734"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_ = vectorizer.fit_transform(train_names.values.astype('U'))\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2C8kj7CmQecn",
    "outputId": "ce1da7b2-dc48-4fd7-fcd3-9f7dc58a4370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      indian       0.98      0.76      0.85      2751\n",
      "  non_indian       0.81      0.99      0.89      2932\n",
      "\n",
      "    accuracy                           0.87      5683\n",
      "   macro avg       0.90      0.87      0.87      5683\n",
      "weighted avg       0.89      0.87      0.87      5683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_,train_labels)\n",
    "\n",
    "X_test = vectorizer.transform(test_names.values.astype('U'))\n",
    "\n",
    "test_predicted = model.predict(X_test)\n",
    "\n",
    "print(classification_report(test_labels,test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tMeZWtDQecn"
   },
   "source": [
    "### Testing on new Names\n",
    "Lets create some names which are not present in the data at all and check the model on these names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6UGuExlrQecn",
    "outputId": "085f95b1-7822-4b40-bdeb-0bc16d432047"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>predictions_nb_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyson</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shailaja</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shyamala</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vishwanathan</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ramanujam</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conan</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kryslovsky</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratnani</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diego</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kakoli</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shreyas</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brayden</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shanon</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           names predictions_nb_cv\n",
       "0        lalitha        non_indian\n",
       "1          tyson        non_indian\n",
       "2       shailaja        non_indian\n",
       "3       shyamala        non_indian\n",
       "4   vishwanathan        non_indian\n",
       "5      ramanujam        non_indian\n",
       "6          conan        non_indian\n",
       "7     kryslovsky        non_indian\n",
       "8        ratnani        non_indian\n",
       "9          diego        non_indian\n",
       "10        kakoli        non_indian\n",
       "11       shreyas        non_indian\n",
       "12       brayden        non_indian\n",
       "13        shanon        non_indian"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_new_names = ['lalitha','tyson','shailaja','shyamala','vishwanathan','ramanujam','conan','kryslovsky',\n",
    "'ratnani','diego','kakoli','shreyas','brayden','shanon']\n",
    "\n",
    "X_new = vectorizer.transform(check_new_names)\n",
    "predictions_nb_cv = model.predict(X_new)\n",
    "test = pd.DataFrame({'names':check_new_names,'predictions_nb_cv':predictions_nb_cv}) \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTBxfE0FQeco"
   },
   "source": [
    "Doesnt do well at all ! But thats expected. Now lets try with subword encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdqbZ-syQeco"
   },
   "source": [
    "### Naive Bayes with SentencePiece Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAKDv4BdSe-H",
    "outputId": "e296ebde-a5fe-4079-b347-8fafdac9dd87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 6.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "C8SOAf0TQeco"
   },
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer,CharBPETokenizer,SentencePieceBPETokenizer,BertWordPieceTokenizer\n",
    "\n",
    "\n",
    "f = open(\"train_names.txt\",\"w\")\n",
    "for each in list(train_names):\n",
    "    f.write(str(each))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8Zfzq9qQecp",
    "outputId": "b3bc1a75-b3ea-4166-b954-3f4b786211bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁raju ▁d ass',\n",
       " '▁hr ▁b ørg e ▁lar s en',\n",
       " '▁l og an ▁mar sh al l',\n",
       " '▁parm ila ▁son a',\n",
       " '▁b ald ev',\n",
       " '▁sam s un g ▁s ▁singh',\n",
       " '▁na om i ▁kir k',\n",
       " '▁rita ▁rasm uss en',\n",
       " '▁ka ish av',\n",
       " '▁brand y ▁mor al es ▁md']"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SentencePieceBPETokenizer()\n",
    "tokenizer.train([\"./train_names.txt\"],vocab_size=2000,min_frequency=2)\n",
    "\n",
    "encoded_tokens = [tokenizer.encode(str(each)).tokens for each in train_names]\n",
    "encoded_tokens_test = [tokenizer.encode(str(each)).tokens for each in test_names]\n",
    "\n",
    "encoded_tokens = [\" \".join(each)  for each in encoded_tokens]\n",
    "encoded_tokens_test = [\" \".join(each)  for each in encoded_tokens_test]\n",
    "\n",
    "encoded_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXKDC15NQecp",
    "outputId": "32f643fc-7f65-4349-fd0f-41a6d36a5430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      indian       0.91      0.94      0.92      2751\n",
      "  non_indian       0.94      0.91      0.92      2932\n",
      "\n",
      "    accuracy                           0.92      5683\n",
      "   macro avg       0.92      0.92      0.92      5683\n",
      "weighted avg       0.92      0.92      0.92      5683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_ = tfidf_vect.fit_transform(encoded_tokens)\n",
    "len(tfidf_vect.get_feature_names())\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_,train_labels)\n",
    "\n",
    "X_test = tfidf_vect.transform(encoded_tokens_test)\n",
    "\n",
    "test_predicted = model.predict(X_test)\n",
    "\n",
    "print(classification_report(test_labels,test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm9jwj9BQecp"
   },
   "source": [
    "Pretty decent. Now lets check on some new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "0ceEbFsVQecq",
    "outputId": "e92efd42-535b-4489-c519-6a2c1895b158"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>predictions_nb_enc_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyson</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shailaja</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shyamala</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vishwanathan</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ramanujam</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conan</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kryslovsky</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratnani</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diego</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kakoli</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shreyas</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brayden</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shanon</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           names predictions_nb_enc_tf\n",
       "0        lalitha                indian\n",
       "1          tyson            non_indian\n",
       "2       shailaja                indian\n",
       "3       shyamala                indian\n",
       "4   vishwanathan                indian\n",
       "5      ramanujam                indian\n",
       "6          conan            non_indian\n",
       "7     kryslovsky            non_indian\n",
       "8        ratnani                indian\n",
       "9          diego            non_indian\n",
       "10        kakoli                indian\n",
       "11       shreyas                indian\n",
       "12       brayden            non_indian\n",
       "13        shanon            non_indian"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens_check = [tokenizer.encode(str(each).lower()).tokens for each in check_new_names]\n",
    "encoded_tokens_check = [\" \".join(each)  for each in encoded_tokens_check]\n",
    "\n",
    "X_new = tfidf_vect.transform(encoded_tokens_check)\n",
    "predictions_nb_enc_tf = model.predict(X_new)\n",
    "test = pd.DataFrame({'names':check_new_names,'predictions_nb_enc_tf':predictions_nb_enc_tf}) \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoGFVLLtQecq"
   },
   "source": [
    "### Character based encoding with LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gHn4C-2jQecq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import Callback\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sPjzJbdcQecq"
   },
   "outputs": [],
   "source": [
    "def char_encoded_representation(data,tokenizer,vocab_size,max_len):\n",
    "    char_index_sentences = tokenizer.texts_to_sequences(data)\n",
    "    sequences = [to_categorical(x, num_classes=vocab_size) for x in char_index_sentences]\n",
    "    X = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg-IkUzYQecr",
    "outputId": "0df06b48-726b-48f4-a053-b639deed5482"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22730, 36, 55)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(str(each)) for each in train_names])\n",
    "# mapping = get_char_mapping(train_names)\n",
    "# vocab_size = len(mapping)\n",
    "\n",
    "tok = Tokenizer(char_level=True)\n",
    "tok.fit_on_texts(train_names)\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "X_train = char_encoded_representation(train_names,tok,vocab_size,max_len)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ptu5SFYeQecr",
    "outputId": "a5f15af9-d519-4c5d-c945-e2040ecf420c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5683, 36, 55)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = char_encoded_representation(test_names,tok,vocab_size,max_len)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "hI9WxhK8Qecr"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "y_train = le.transform(train_labels)\n",
    "y_test = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cRFEYg2rQecs"
   },
   "outputs": [],
   "source": [
    "# Model Specification\n",
    "\n",
    "def build_model(hidden_units,max_len,vocab_size):\n",
    "    model = Sequential()\n",
    "    # model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "    model.add(LSTM(hidden_units,input_shape=(max_len,vocab_size)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XdX2tEVXQect"
   },
   "outputs": [],
   "source": [
    "class myCallback(Callback): \n",
    "    def __init__(self,X_test,y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        loss,acc = model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dKsjch4Qecu",
    "outputId": "05061a7e-78a1-4a8f-bf76-4a5f12be5360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               62400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 62,501\n",
      "Trainable params: 62,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "356/356 [==============================] - 23s 6ms/step - loss: 0.5090 - accuracy: 0.7388\n",
      "\n",
      "Testing loss: 0.37326768040657043, acc: 0.8319549560546875\n",
      "\n",
      "Epoch 2/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.3573 - accuracy: 0.8420\n",
      "\n",
      "Testing loss: 0.317292183637619, acc: 0.8599331378936768\n",
      "\n",
      "Epoch 3/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.3027 - accuracy: 0.8703\n",
      "\n",
      "Testing loss: 0.2842683792114258, acc: 0.8826324343681335\n",
      "\n",
      "Epoch 4/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.2823 - accuracy: 0.8836\n",
      "\n",
      "Testing loss: 0.2879863381385803, acc: 0.881928563117981\n",
      "\n",
      "Epoch 5/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.2521 - accuracy: 0.8929\n",
      "\n",
      "Testing loss: 0.2609037458896637, acc: 0.8924863338470459\n",
      "\n",
      "Epoch 6/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.2274 - accuracy: 0.9068\n",
      "\n",
      "Testing loss: 0.23408614099025726, acc: 0.9030441641807556\n",
      "\n",
      "Epoch 7/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.2096 - accuracy: 0.9114\n",
      "\n",
      "Testing loss: 0.22307248413562775, acc: 0.9111384749412537\n",
      "\n",
      "Epoch 8/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1949 - accuracy: 0.9211\n",
      "\n",
      "Testing loss: 0.21081534028053284, acc: 0.9144817590713501\n",
      "\n",
      "Epoch 9/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.1877 - accuracy: 0.9223\n",
      "\n",
      "Testing loss: 0.20872098207473755, acc: 0.9194087386131287\n",
      "\n",
      "Epoch 10/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1727 - accuracy: 0.9281\n",
      "\n",
      "Testing loss: 0.19660259783267975, acc: 0.9220482110977173\n",
      "\n",
      "Epoch 11/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1569 - accuracy: 0.9361\n",
      "\n",
      "Testing loss: 0.18622782826423645, acc: 0.9290867447853088\n",
      "\n",
      "Epoch 12/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1508 - accuracy: 0.9411\n",
      "\n",
      "Testing loss: 0.18348222970962524, acc: 0.9290867447853088\n",
      "\n",
      "Epoch 13/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1352 - accuracy: 0.9478\n",
      "\n",
      "Testing loss: 0.19013002514839172, acc: 0.9280309677124023\n",
      "\n",
      "Epoch 14/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1326 - accuracy: 0.9486\n",
      "\n",
      "Testing loss: 0.18274188041687012, acc: 0.9340137243270874\n",
      "\n",
      "Epoch 15/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1291 - accuracy: 0.9510\n",
      "\n",
      "Testing loss: 0.1742086112499237, acc: 0.9348935484886169\n",
      "\n",
      "Epoch 16/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1106 - accuracy: 0.9570\n",
      "\n",
      "Testing loss: 0.18000170588493347, acc: 0.9361252784729004\n",
      "\n",
      "Epoch 17/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1034 - accuracy: 0.9604\n",
      "\n",
      "Testing loss: 0.18869580328464508, acc: 0.9311982989311218\n",
      "\n",
      "Epoch 18/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9669\n",
      "\n",
      "Testing loss: 0.16779102385044098, acc: 0.9396445751190186\n",
      "\n",
      "Epoch 19/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0873 - accuracy: 0.9656\n",
      "\n",
      "Testing loss: 0.17190921306610107, acc: 0.9414041638374329\n",
      "\n",
      "Epoch 20/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0864 - accuracy: 0.9679\n",
      "\n",
      "Testing loss: 0.17558710277080536, acc: 0.9384127855300903\n",
      "\n",
      "Epoch 21/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0765 - accuracy: 0.9714\n",
      "\n",
      "Testing loss: 0.1740514039993286, acc: 0.940876305103302\n",
      "\n",
      "Epoch 22/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0772 - accuracy: 0.9711\n",
      "\n",
      "Testing loss: 0.17564907670021057, acc: 0.9436917304992676\n",
      "\n",
      "Epoch 23/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0635 - accuracy: 0.9760\n",
      "\n",
      "Testing loss: 0.16951006650924683, acc: 0.9433397650718689\n",
      "\n",
      "Epoch 24/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9771\n",
      "\n",
      "Testing loss: 0.1719386726617813, acc: 0.9475629329681396\n",
      "\n",
      "Epoch 25/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0596 - accuracy: 0.9784\n",
      "\n",
      "Testing loss: 0.16527776420116425, acc: 0.9477388858795166\n",
      "\n",
      "Epoch 26/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0569 - accuracy: 0.9791\n",
      "\n",
      "Testing loss: 0.16641530394554138, acc: 0.9463311433792114\n",
      "\n",
      "Epoch 27/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9804\n",
      "\n",
      "Testing loss: 0.16060248017311096, acc: 0.9507302641868591\n",
      "\n",
      "Epoch 28/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0468 - accuracy: 0.9838\n",
      "\n",
      "Testing loss: 0.1661897450685501, acc: 0.9498504400253296\n",
      "\n",
      "Epoch 29/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9849\n",
      "\n",
      "Testing loss: 0.16914913058280945, acc: 0.9500263929367065\n",
      "\n",
      "Epoch 30/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0423 - accuracy: 0.9862\n",
      "\n",
      "Testing loss: 0.1835882067680359, acc: 0.9458032846450806\n",
      "\n",
      "Epoch 31/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.9847\n",
      "\n",
      "Testing loss: 0.169280007481575, acc: 0.9482667446136475\n",
      "\n",
      "Epoch 32/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9845\n",
      "\n",
      "Testing loss: 0.16257251799106598, acc: 0.9496744871139526\n",
      "\n",
      "Epoch 33/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9871\n",
      "\n",
      "Testing loss: 0.17943677306175232, acc: 0.9509062170982361\n",
      "\n",
      "Epoch 34/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0328 - accuracy: 0.9878\n",
      "\n",
      "Testing loss: 0.17152179777622223, acc: 0.9517860412597656\n",
      "\n",
      "Epoch 35/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0344 - accuracy: 0.9891\n",
      "\n",
      "Testing loss: 0.2097325474023819, acc: 0.9403483867645264\n",
      "\n",
      "Epoch 36/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0420 - accuracy: 0.9839\n",
      "\n",
      "Testing loss: 0.17967237532138824, acc: 0.9528418183326721\n",
      "\n",
      "Epoch 37/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9889\n",
      "\n",
      "Testing loss: 0.1767001897096634, acc: 0.953369677066803\n",
      "\n",
      "Epoch 38/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9924\n",
      "\n",
      "Testing loss: 0.18579037487506866, acc: 0.9542495012283325\n",
      "\n",
      "Epoch 39/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0225 - accuracy: 0.9925\n",
      "\n",
      "Testing loss: 0.1938556730747223, acc: 0.9507302641868591\n",
      "\n",
      "Epoch 40/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9917\n",
      "\n",
      "Testing loss: 0.1940569281578064, acc: 0.9482667446136475\n",
      "\n",
      "Epoch 41/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0284 - accuracy: 0.9901\n",
      "\n",
      "Testing loss: 0.1861235648393631, acc: 0.9535456895828247\n",
      "\n",
      "Epoch 42/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0220 - accuracy: 0.9930\n",
      "\n",
      "Testing loss: 0.19422213733196259, acc: 0.9537216424942017\n",
      "\n",
      "Epoch 43/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9940\n",
      "\n",
      "Testing loss: 0.1849461942911148, acc: 0.9556572437286377\n",
      "\n",
      "Epoch 44/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9933\n",
      "\n",
      "Testing loss: 0.19789773225784302, acc: 0.9530177712440491\n",
      "\n",
      "Epoch 45/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0199 - accuracy: 0.9938\n",
      "\n",
      "Testing loss: 0.19549942016601562, acc: 0.9537216424942017\n",
      "\n",
      "Epoch 46/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0206 - accuracy: 0.9928\n",
      "\n",
      "Testing loss: 0.19613513350486755, acc: 0.9530177712440491\n",
      "\n",
      "Epoch 47/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0248 - accuracy: 0.9914\n",
      "\n",
      "Testing loss: 0.18855313956737518, acc: 0.9567130208015442\n",
      "\n",
      "Epoch 48/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0208 - accuracy: 0.9927\n",
      "\n",
      "Testing loss: 0.19994507730007172, acc: 0.9526658654212952\n",
      "\n",
      "Epoch 49/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0182 - accuracy: 0.9940\n",
      "\n",
      "Testing loss: 0.19607430696487427, acc: 0.9570649266242981\n",
      "\n",
      "Epoch 50/50\n",
      "356/356 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9952\n",
      "\n",
      "Testing loss: 0.20335201919078827, acc: 0.9547774195671082\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f699f202e10>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(100,max_len,vocab_size)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64,callbacks=myCallback(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "Qs17Kx8pQecx",
    "outputId": "b3d42290-1342-4bbe-e6c8-111a0ea1f0e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>predictions_lstm_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyson</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shailaja</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shyamala</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vishwanathan</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ramanujam</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conan</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kryslovsky</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratnani</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diego</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kakoli</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shreyas</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brayden</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shanon</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           names predictions_lstm_char\n",
       "0        lalitha                indian\n",
       "1          tyson            non_indian\n",
       "2       shailaja                indian\n",
       "3       shyamala                indian\n",
       "4   vishwanathan                indian\n",
       "5      ramanujam                indian\n",
       "6          conan            non_indian\n",
       "7     kryslovsky            non_indian\n",
       "8        ratnani                indian\n",
       "9          diego            non_indian\n",
       "10        kakoli                indian\n",
       "11       shreyas                indian\n",
       "12       brayden            non_indian\n",
       "13        shanon            non_indian"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predict = char_encoded_representation(check_new_names,tok,vocab_size,max_len)\n",
    "\n",
    "predictions_prob = model.predict(X_predict)\n",
    "predictions = np.array(predictions_prob)\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions = np.squeeze(predictions)\n",
    "predictions_lstm_char = le.inverse_transform(list(predictions.astype(int)))\n",
    "test = pd.DataFrame({'names':check_new_names,'predictions_lstm_char':predictions_lstm_char}) \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Xrh3VDxQecy"
   },
   "source": [
    "### SentencePiece Encoding with LSTM\n",
    "\n",
    "Lets also check with a encoding using the **SentencePiece Encoding** we used for Naive Bayes. But now we will use it with an LSTM with a much smaller vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "rog3ACrUQecz"
   },
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer,CharBPETokenizer,SentencePieceBPETokenizer,BertWordPieceTokenizer\n",
    "vocab_size = 200\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "tokenizer.train([\"./train_names.txt\"],vocab_size=vocab_size,min_frequency=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "IfBJHrpzQecz"
   },
   "outputs": [],
   "source": [
    "def sent_piece_encoded_representation(data,tokenizer):\n",
    "    encoded_tokens = [tokenizer.encode(str(each)).ids for each in data]\n",
    "    sequences = [to_categorical(x, num_classes=vocab_size) for x in encoded_tokens]\n",
    "    X = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9NGUET6QQec0"
   },
   "outputs": [],
   "source": [
    "max_len = max([len(str(each)) for each in train_names])\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "y_train = le.transform(train_labels)\n",
    "y_test = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VS3LsCnQec0",
    "outputId": "8c9290e5-6547-491c-dbe6-a46a8c8fb479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22730, 36, 200)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sent_piece_encoded_representation(train_names,tokenizer)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BT5XitzQec0",
    "outputId": "bf6afccd-69f4-4938-f1f1-5cd486aae0ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5683, 36, 200)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = sent_piece_encoded_representation(test_names,tokenizer)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdSzLPUvQec1",
    "outputId": "21c5f21b-03c7-4b68-c785-36f0caee6ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 120,501\n",
      "Trainable params: 120,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "356/356 [==============================] - 4s 6ms/step - loss: 0.4723 - accuracy: 0.7855\n",
      "\n",
      "Testing loss: 0.28326326608657837, acc: 0.8852718472480774\n",
      "\n",
      "Epoch 2/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.2724 - accuracy: 0.8866\n",
      "\n",
      "Testing loss: 0.2601301968097687, acc: 0.8926623463630676\n",
      "\n",
      "Epoch 3/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.2512 - accuracy: 0.8951\n",
      "\n",
      "Testing loss: 0.24539077281951904, acc: 0.9019883871078491\n",
      "\n",
      "Epoch 4/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.2288 - accuracy: 0.9067\n",
      "\n",
      "Testing loss: 0.22528895735740662, acc: 0.9088509678840637\n",
      "\n",
      "Epoch 5/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.2183 - accuracy: 0.9085\n",
      "\n",
      "Testing loss: 0.21613946557044983, acc: 0.9120182991027832\n",
      "\n",
      "Epoch 6/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1936 - accuracy: 0.9187\n",
      "\n",
      "Testing loss: 0.20123088359832764, acc: 0.9180010557174683\n",
      "\n",
      "Epoch 7/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1756 - accuracy: 0.9296\n",
      "\n",
      "Testing loss: 0.19604331254959106, acc: 0.9211683869361877\n",
      "\n",
      "Epoch 8/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1638 - accuracy: 0.9341\n",
      "\n",
      "Testing loss: 0.19145280122756958, acc: 0.9215203523635864\n",
      "\n",
      "Epoch 9/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1442 - accuracy: 0.9433\n",
      "\n",
      "Testing loss: 0.18083615601062775, acc: 0.9287348389625549\n",
      "\n",
      "Epoch 10/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1318 - accuracy: 0.9464\n",
      "\n",
      "Testing loss: 0.1752193421125412, acc: 0.9304944276809692\n",
      "\n",
      "Epoch 11/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1263 - accuracy: 0.9524\n",
      "\n",
      "Testing loss: 0.1688050627708435, acc: 0.9350695013999939\n",
      "\n",
      "Epoch 12/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1118 - accuracy: 0.9557\n",
      "\n",
      "Testing loss: 0.16348323225975037, acc: 0.9357733726501465\n",
      "\n",
      "Epoch 13/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.1098 - accuracy: 0.9568\n",
      "\n",
      "Testing loss: 0.16503970324993134, acc: 0.9364771842956543\n",
      "\n",
      "Epoch 14/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0923 - accuracy: 0.9643\n",
      "\n",
      "Testing loss: 0.16633637249469757, acc: 0.9398205280303955\n",
      "\n",
      "Epoch 15/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0886 - accuracy: 0.9658\n",
      "\n",
      "Testing loss: 0.1713508665561676, acc: 0.9380608797073364\n",
      "\n",
      "Epoch 16/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0787 - accuracy: 0.9686\n",
      "\n",
      "Testing loss: 0.16374702751636505, acc: 0.9385887980461121\n",
      "\n",
      "Epoch 17/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0776 - accuracy: 0.9697\n",
      "\n",
      "Testing loss: 0.1666749268770218, acc: 0.9426359534263611\n",
      "\n",
      "Epoch 18/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0643 - accuracy: 0.9758\n",
      "\n",
      "Testing loss: 0.16384387016296387, acc: 0.9436917304992676\n",
      "\n",
      "Epoch 19/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0592 - accuracy: 0.9797\n",
      "\n",
      "Testing loss: 0.17450428009033203, acc: 0.9440436363220215\n",
      "\n",
      "Epoch 20/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0579 - accuracy: 0.9781\n",
      "\n",
      "Testing loss: 0.1760880947113037, acc: 0.9417561292648315\n",
      "\n",
      "Epoch 21/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0498 - accuracy: 0.9800\n",
      "\n",
      "Testing loss: 0.16849786043167114, acc: 0.9466831088066101\n",
      "\n",
      "Epoch 22/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0494 - accuracy: 0.9820\n",
      "\n",
      "Testing loss: 0.17010565102100372, acc: 0.9489706158638\n",
      "\n",
      "Epoch 23/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9851\n",
      "\n",
      "Testing loss: 0.1689690202474594, acc: 0.949322521686554\n",
      "\n",
      "Epoch 24/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.9857\n",
      "\n",
      "Testing loss: 0.1797506958246231, acc: 0.9435157775878906\n",
      "\n",
      "Epoch 25/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0396 - accuracy: 0.9859\n",
      "\n",
      "Testing loss: 0.1655765175819397, acc: 0.9489706158638\n",
      "\n",
      "Epoch 26/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0331 - accuracy: 0.9888\n",
      "\n",
      "Testing loss: 0.17249412834644318, acc: 0.9498504400253296\n",
      "\n",
      "Epoch 27/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9889\n",
      "\n",
      "Testing loss: 0.17760440707206726, acc: 0.9484426975250244\n",
      "\n",
      "Epoch 28/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9899\n",
      "\n",
      "Testing loss: 0.18543151021003723, acc: 0.949322521686554\n",
      "\n",
      "Epoch 29/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0349 - accuracy: 0.9877\n",
      "\n",
      "Testing loss: 0.19534631073474884, acc: 0.947035014629364\n",
      "\n",
      "Epoch 30/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9899\n",
      "\n",
      "Testing loss: 0.1929541379213333, acc: 0.9489706158638\n",
      "\n",
      "Epoch 31/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0230 - accuracy: 0.9929\n",
      "\n",
      "Testing loss: 0.22395937144756317, acc: 0.947210967540741\n",
      "\n",
      "Epoch 32/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "\n",
      "Testing loss: 0.21026767790317535, acc: 0.9498504400253296\n",
      "\n",
      "Epoch 33/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9929\n",
      "\n",
      "Testing loss: 0.20476600527763367, acc: 0.9507302641868591\n",
      "\n",
      "Epoch 34/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9942\n",
      "\n",
      "Testing loss: 0.18838347494602203, acc: 0.9540735483169556\n",
      "\n",
      "Epoch 35/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0180 - accuracy: 0.9942\n",
      "\n",
      "Testing loss: 0.20661751925945282, acc: 0.9530177712440491\n",
      "\n",
      "Epoch 36/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0162 - accuracy: 0.9946\n",
      "\n",
      "Testing loss: 0.21142737567424774, acc: 0.9505543112754822\n",
      "\n",
      "Epoch 37/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9923\n",
      "\n",
      "Testing loss: 0.20920126140117645, acc: 0.951082170009613\n",
      "\n",
      "Epoch 38/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0163 - accuracy: 0.9948\n",
      "\n",
      "Testing loss: 0.21080464124679565, acc: 0.9519619941711426\n",
      "\n",
      "Epoch 39/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "\n",
      "Testing loss: 0.2158057689666748, acc: 0.9524898529052734\n",
      "\n",
      "Epoch 40/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0167 - accuracy: 0.9946\n",
      "\n",
      "Testing loss: 0.21493755280971527, acc: 0.95125812292099\n",
      "\n",
      "Epoch 41/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9927\n",
      "\n",
      "Testing loss: 0.20136503875255585, acc: 0.9551293253898621\n",
      "\n",
      "Epoch 42/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0141 - accuracy: 0.9962\n",
      "\n",
      "Testing loss: 0.21293598413467407, acc: 0.9517860412597656\n",
      "\n",
      "Epoch 43/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0128 - accuracy: 0.9955\n",
      "\n",
      "Testing loss: 0.21515382826328278, acc: 0.9538975954055786\n",
      "\n",
      "Epoch 44/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "\n",
      "Testing loss: 0.19282107055187225, acc: 0.9582966566085815\n",
      "\n",
      "Epoch 45/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "\n",
      "Testing loss: 0.2047889232635498, acc: 0.9561851024627686\n",
      "\n",
      "Epoch 46/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0104 - accuracy: 0.9967\n",
      "\n",
      "Testing loss: 0.21293002367019653, acc: 0.9577687978744507\n",
      "\n",
      "Epoch 47/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0106 - accuracy: 0.9965\n",
      "\n",
      "Testing loss: 0.21561294794082642, acc: 0.957416832447052\n",
      "\n",
      "Epoch 48/50\n",
      "356/356 [==============================] - 2s 6ms/step - loss: 0.0095 - accuracy: 0.9967\n",
      "\n",
      "Testing loss: 0.20936091244220734, acc: 0.9586486220359802\n",
      "\n",
      "Epoch 49/50\n",
      "356/356 [==============================] - 2s 7ms/step - loss: 0.0124 - accuracy: 0.9958\n",
      "\n",
      "Testing loss: 0.22349531948566437, acc: 0.9544254541397095\n",
      "\n",
      "Epoch 50/50\n",
      "356/356 [==============================] - 2s 7ms/step - loss: 0.0174 - accuracy: 0.9944\n",
      "\n",
      "Testing loss: 0.20372852683067322, acc: 0.9558331966400146\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f694bfe9050>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(100,max_len,vocab_size)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64,callbacks=myCallback(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "qOwVSFSBQec1"
   },
   "outputs": [],
   "source": [
    "X_predict = sent_piece_encoded_representation(check_new_names,tokenizer)\n",
    "\n",
    "predictions_prob = model.predict(X_predict)\n",
    "predictions = np.array(predictions_prob)\n",
    "predictions[np.where(predictions > 0.5)[0]] = 1\n",
    "predictions[np.where(predictions <= 0.5)[0]] = 0\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "predictions_lstm_sent_enc = le.inverse_transform(list(predictions.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "50EZHx3ZQec1",
    "outputId": "b2678995-cb10-45b0-c7f2-20bec1328334"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>predictions_lstm_sent_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tyson</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shailaja</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shyamala</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vishwanathan</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ramanujam</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conan</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kryslovsky</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratnani</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diego</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kakoli</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shreyas</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brayden</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shanon</td>\n",
       "      <td>non_indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           names predictions_lstm_sent_enc\n",
       "0        lalitha                    indian\n",
       "1          tyson                non_indian\n",
       "2       shailaja                    indian\n",
       "3       shyamala                    indian\n",
       "4   vishwanathan                    indian\n",
       "5      ramanujam                    indian\n",
       "6          conan                non_indian\n",
       "7     kryslovsky                non_indian\n",
       "8        ratnani                    indian\n",
       "9          diego                    indian\n",
       "10        kakoli                    indian\n",
       "11       shreyas                non_indian\n",
       "12       brayden                non_indian\n",
       "13        shanon                non_indian"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame({'names':check_new_names,'predictions_lstm_sent_enc':predictions_lstm_sent_enc}) \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "m2DPWSuYQec2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "SjnUm_6uQec2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "24.Classify Nationalities .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
